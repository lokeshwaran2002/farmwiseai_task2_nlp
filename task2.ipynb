{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "To create a topic-based post recommendation system using Generative AI, you can follow the outlined approach:\n",
        "\n",
        "User Topic Profiling:\n",
        "Objective: Create a user profile based on their interests, derived from their posts."
      ],
      "metadata": {
        "id": "LSYG1X3TPhIv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenization and Embedding:\n",
        "\n",
        "Tokenize and embed user posts using a Generative AI model such as GPT-4/3.5.\n",
        "Extract contextual embeddings for each word in the post.\n",
        "Topic Extraction:\n",
        "\n",
        "Utilize the contextual embeddings to identify key topics within each user post.\n",
        "Limit the number of topics to 20, with a maximum of 10 topics per user post.\n",
        "Post Topic Profiling:\n",
        "Objective: Assign topics to each post.\n",
        "\n",
        "Tokenization and Embedding:\n",
        "\n",
        "Tokenize and embed each post using the same Generative AI model.\n",
        "Extract contextual embeddings for each word in the post.\n",
        "Topic Extraction:\n",
        "\n",
        "Use contextual embeddings to identify key topics within each post.\n",
        "Limit the number of topics to 20, matching the user profile limit.\n",
        "Recommendation Engine:\n",
        "Objective: Match posts with the top 10 most relevant users based on their interests.\n"
      ],
      "metadata": {
        "id": "zysl8jdcPnQc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and testing datasets\n",
        "with open(\"content/Reddit_data_train.json\", 'r') as f_train, open(\"content/Reddit_data_test.json\", 'r') as f_test:\n",
        "    train_data = json.load(f_train)\n",
        "    test_data = json.load(f_test)\n",
        "\n",
        "# Explore the structure of the datasets\n",
        "print(\"Training Data Sample:\")\n",
        "if isinstance(train_data, list):\n",
        "    print(train_data[:2])\n",
        "else:\n",
        "    # Print the first two elements if it's not a list\n",
        "    for i, (key, value) in enumerate(train_data.items()):\n",
        "        print(f\"{key}: {value}\")\n",
        "        if i == 1:\n",
        "            break\n",
        "\n",
        "print(\"\\nTesting Data Sample:\")\n",
        "if isinstance(test_data, list):\n",
        "    print(test_data[:2])\n",
        "else:\n",
        "    # Print the first two elements if it's not a list\n",
        "    for i, (key, value) in enumerate(test_data.items()):\n",
        "        print(f\"{key}: {value}\")\n",
        "        if i == 1:\n",
        "            break"
      ],
      "metadata": {
        "id": "4yX1C0IcQn2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: User Topic Profiling\n",
        "# Simplified user profiles\n",
        "user_profiles = {\n",
        "    \"user1\": [\"Blockchain\", \"Cryptocurrency\", \"Technology\"],\n",
        "    \"user2\": [\"Finance\", \"Investing\", \"Stocks\"],\n",
        "    # ... more user profiles ...\n",
        "}\n",
        "\n",
        "# Step 2: Post Topic Profiling\n",
        "# Simplified post topics\n",
        "post_topics = {\n",
        "    \"post1\": [\"Blockchain\", \"Cryptocurrency\", \"Technology\"],\n",
        "    \"post2\": [\"Finance\", \"Investing\", \"Stocks\"],\n",
        "    # ... more post topics ...\n",
        "}\n",
        "\n",
        "# Step 3: Recommendation Engine\n",
        "def recommend_posts(user_profile, post_topics):\n",
        "    # Calculate topic relevance scores\n",
        "    relevance_scores = {post: len(set(user_profile) & set(topics)) for post, topics in post_topics.items()}\n",
        "\n",
        "    # Sort posts by relevance\n",
        "    sorted_posts = sorted(relevance_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Return top N recommended posts\n",
        "    return sorted_posts[:5]  # Adjust the number of recommendations as needed\n",
        "\n",
        "# Step 4: Evaluation\n",
        "def evaluate_recommendations(predictions, ground_truth):\n",
        "    # Simplified evaluation using Jaccard Similarity\n",
        "    intersection = len(set(predictions) & set(ground_truth))\n",
        "    union = len(set(predictions) | set(ground_truth))\n",
        "    jaccard_similarity = intersection / union\n",
        "    return jaccard_similarity\n",
        "\n",
        "# Step 5: Deliverables\n",
        "class RecommendationSystem:\n",
        "    def __init__(self, user_profiles, post_topics):\n",
        "        self.user_profiles = user_profiles\n",
        "        self.post_topics = post_topics\n",
        "\n",
        "    def recommend_posts_for_user(self, user_id):\n",
        "        user_profile = self.user_profiles.get(user_id, [])\n",
        "        if user_profile:\n",
        "            return recommend_posts(user_profile, self.post_topics)\n",
        "        else:\n",
        "            return []\n"
      ],
      "metadata": {
        "id": "uDOTzVvUOicj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 6: Run the System (Simplified)\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    system = RecommendationSystem(user_profiles, post_topics)\n",
        "    user_id = \"user1\"\n",
        "    recommendations = system.recommend_posts_for_user(user_id)\n",
        "    print(\"Recommendations for {}: {}\".format(user_id, recommendations))\n",
        "\n",
        "    # Example Evaluation\n",
        "    ground_truth = [\"post1\", \"post2\"]\n",
        "    jaccard_similarity = evaluate_recommendations(recommendations, ground_truth)\n",
        "    print(\"Jaccard Similarity:\", jaccard_similarity)\n"
      ],
      "metadata": {
        "id": "FZjyagygPBNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers\n"
      ],
      "metadata": {
        "id": "YqdqEujfPN72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2Tokenizer, TFGPT2Model\n",
        "\n",
        "# Step 7: Advanced Topic Extraction\n",
        "class TopicExtractor:\n",
        "    def __init__(self):\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
        "        self.model = TFGPT2Model.from_pretrained(\"gpt2\")\n",
        "\n",
        "    def extract_topics(self, text):\n",
        "        # Tokenize input text\n",
        "        inputs = self.tokenizer(text, return_tensors=\"tf\")\n",
        "\n",
        "        # Get model output\n",
        "        outputs = self.model(inputs[\"input_ids\"])\n",
        "\n",
        "        # Extract topics from model output\n",
        "        topics = self.tokenizer.batch_decode(outputs[\"last_hidden_state\"][0].numpy(), skip_special_tokens=True)\n",
        "\n",
        "        return topics\n",
        "\n",
        "# Step 8: Enhance User Profiling with Topic Extraction\n",
        "topic_extractor = TopicExtractor()\n",
        "\n",
        "for user, posts in user_profiles.items():\n",
        "    user_interests = []\n",
        "    for post in posts:\n",
        "        topics = topic_extractor.extract_topics(post)\n",
        "        user_interests.extend(topics)\n",
        "    user_profiles[user] = list(set(user_interests))[:10]  # Limit to top 10 topics per user\n"
      ],
      "metadata": {
        "id": "4hndt4VGPHz7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "User-Post Matching:\n",
        "\n",
        "Compare the identified topics of a post with the topics in user profiles.\n",
        "Calculate a relevance score based on topic matches.\n",
        "Top User Selection:\n",
        "\n",
        "Identify the top 10 users with the highest relevance scores for each post.\n",
        "Evaluation:\n",
        "Metrics: Use Normalized Discounted Cumulative Gain (NDCG) and Jaccard similarity to evaluate the effectiveness of the recommendations.\n",
        "\n",
        "NDCG:\n",
        "\n",
        "Evaluate the ranking of recommended posts against the ground truth data.\n",
        "Measure the quality of the recommendations using NDCG.\n",
        "Jaccard Similarity:\n",
        "\n",
        "Calculate Jaccard similarity between recommended users and users who interacted with the test post.\n",
        "Deliverables:"
      ],
      "metadata": {
        "id": "PSoIiriYPvYO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Enhance Recommendation Engine\n",
        "class RecommendationEngine:\n",
        "    def __init__(self, user_profiles, posts):\n",
        "        self.user_profiles = user_profiles\n",
        "        self.posts = posts\n",
        "\n",
        "    def recommend_posts(self, user_id):\n",
        "        user_interests = self.user_profiles[user_id]\n",
        "\n",
        "        # Find posts with shared topics\n",
        "        recommended_posts = []\n",
        "        for post_id, post_content in self.posts.items():\n",
        "            post_topics = topic_extractor.extract_topics(post_content)\n",
        "            common_topics = set(user_interests).intersection(post_topics)\n",
        "            if common_topics:\n",
        "                recommended_posts.append(post_id)\n",
        "\n",
        "        return recommended_posts\n"
      ],
      "metadata": {
        "id": "IVkuSBSLPTzX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Step 10: Use the Enhanced Recommendation Engine\n",
        "recommendation_engine = RecommendationEngine(user_profiles, posts)\n",
        "\n",
        "# Example: Recommend posts for a specific user\n",
        "user_id_to_recommend = \"S1NCL41R\"\n",
        "recommended_posts = recommendation_engine.recommend_posts(user_id_to_recommend)\n",
        "print(f\"Recommended posts for user {user_id_to_recommend}: {recommended_posts}\")\n",
        "# Step 11: Evaluation Metrics\n",
        "def evaluate_recommendations(ground_truth, recommendations):\n",
        "    # Calculate Jaccard similarity\n",
        "    def jaccard_similarity(set1, set2):\n",
        "        intersection = len(set1.intersection(set2))\n",
        "        union = len(set1.union(set2))\n",
        "        return intersection / union if union != 0 else 0.0\n",
        "\n",
        "    # Calculate NDCG\n",
        "    def ndcg(relevance_order):\n",
        "        dcg = sum(1.0 / math.log2(i + 2) if relevance_order[i] == 1 else 0.0 for i in range(len(relevance_order)))\n",
        "        idcg = sum(1.0 / math.log2(i + 2) for i in range(len(relevance_order)))\n",
        "        return dcg / idcg if idcg != 0 else 0.0\n",
        "\n",
        "    total_jaccard_similarity = 0.0\n",
        "    total_ndcg = 0.0\n",
        "\n",
        "    for post_id, ground_truth_data in ground_truth.items():\n",
        "        ground_truth_users = {data[\"user\"] for data in ground_truth_data}\n",
        "        recommended_users = {user_id for user_id in recommendations[post_id]}\n",
        "\n",
        "        # Calculate Jaccard similarity for each post\n",
        "        jaccard_sim = jaccard_similarity(ground_truth_users, recommended_users)\n",
        "        total_jaccard_similarity += jaccard_sim\n",
        "\n",
        "        # Create a relevance order for NDCG\n",
        "        relevance_order = [1 if user_id in ground_truth_users else 0 for user_id in recommendations[post_id]]\n",
        "        # Calculate NDCG for each post\n",
        "        post_ndcg = ndcg(relevance_order)\n",
        "        total_ndcg += post_ndcg\n",
        "\n",
        "    # Average over all posts\n",
        "    avg_jaccard_similarity = total_jaccard_similarity / len(ground_truth)\n",
        "    avg_ndcg = total_ndcg / len(ground_truth)\n",
        "\n",
        "    return avg_jaccard_similarity, avg_ndcg\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZeAbv5JTPTus"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 12: Evaluate the Recommendation System\n",
        "avg_jaccard_similarity, avg_ndcg = evaluate_recommendations(ground_truth, recommendations)\n",
        "print(f\"Average Jaccard Similarity: {avg_jaccard_similarity}\")\n",
        "print(f\"Average NDCG: {avg_ndcg}\")"
      ],
      "metadata": {
        "id": "HOZCha_SRAKu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}